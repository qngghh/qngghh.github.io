{
    "version": "https://jsonfeed.org/version/1",
    "title": "Supernova • All posts by \"nlp\" tag",
    "description": "小派过气画家",
    "home_page_url": "https://www.kitx86.com",
    "items": [
        {
            "id": "https://www.kitx86.com/2022/05/25/ml-dl-nlp-jing-sai-shu-ju-chu-li/",
            "url": "https://www.kitx86.com/2022/05/25/ml-dl-nlp-jing-sai-shu-ju-chu-li/",
            "title": "ML-DL-nlp竞赛数据处理",
            "date_published": "2022-05-25T14:11:03.000Z",
            "content_html": "<h3 id=\"kaggle-天池竞赛环境\"><a href=\"#kaggle-天池竞赛环境\" class=\"headerlink\" title=\"kaggle/天池竞赛环境\"></a>kaggle/天池竞赛环境</h3><p>1.设置一个训练、推理随机种子</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">seed_everything</span><span class=\"token punctuation\">(</span>seed<span class=\"token operator\">=</span><span class=\"token number\">42</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    random<span class=\"token punctuation\">.</span>seed<span class=\"token punctuation\">(</span>seed<span class=\"token punctuation\">)</span>\n    os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'PYTHONHASHSEED'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>seed<span class=\"token punctuation\">)</span>\n    os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'TF_CUDNN_DETERMINISTIC'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'1'</span>\n    np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>seed<span class=\"token punctuation\">(</span>seed<span class=\"token punctuation\">)</span>\n    tf<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>set_seed<span class=\"token punctuation\">(</span>seed<span class=\"token punctuation\">)</span>\n    \nseed_everything<span class=\"token punctuation\">(</span>seed<span class=\"token operator\">=</span><span class=\"token number\">42</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>2.在nlp中大多数都是使用 deberta系列来完成训练的，很傻瓜只需要会用 model 来训练就好了</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># tokenizer 在推理时是非常重要的</span>\ntokenizer <span class=\"token operator\">=</span> transformers<span class=\"token punctuation\">.</span>AutoTokenizer<span class=\"token punctuation\">.</span>from_pretrained<span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">.</span>model_name<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Context tokens. </span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'context_token'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'['</span> <span class=\"token operator\">+</span> test<span class=\"token punctuation\">.</span>context <span class=\"token operator\">+</span> <span class=\"token string\">']'</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'sep_token'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'[SEP]'</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'cls_token'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'[CLS]'</span>\ncontext_tokens <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>test<span class=\"token punctuation\">.</span>context_token<span class=\"token punctuation\">.</span>unique<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntokenizer<span class=\"token punctuation\">.</span>add_special_tokens<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">'additional_special_tokens'</span><span class=\"token punctuation\">:</span> context_tokens<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n",
            "tags": [
                "kaggle",
                "nlp"
            ]
        },
        {
            "id": "https://www.kitx86.com/2022/05/09/ml-dl-zi-ran-yu-yan-chu-li-yi-wen/",
            "url": "https://www.kitx86.com/2022/05/09/ml-dl-zi-ran-yu-yan-chu-li-yi-wen/",
            "title": "ML-Dl-自然语言处理疑问",
            "date_published": "2022-05-09T12:49:54.000Z",
            "content_html": "<p>1.机器翻译任务中如何解决未登录词的翻译问题？</p>\n<p>2.解决翻译任务中双语料不足的方法？</p>\n<p>3.如何使用 CNN 和 RNN 来解决 问题系统任务中的长距离依赖问题？ 对比 Transformer有什么好的新意？</p>\n<p>4.在文本段落编码是如何结合问题信息？好处是什么？</p>\n<p>5.如何对文本中词的位置信息进行编码？</p>\n<p>6.语言模型的任务形式是什么？语言模型如何提升其它自然语言处理任务的效果？</p>\n<p>7.常见的词嵌入模型？它们之间联系和区别？</p>\n",
            "tags": [
                "深度学习",
                "NLP"
            ]
        },
        {
            "id": "https://www.kitx86.com/2022/05/09/ml-dl-zi-ran-yu-yan-chu-li-ji-chu/",
            "url": "https://www.kitx86.com/2022/05/09/ml-dl-zi-ran-yu-yan-chu-li-ji-chu/",
            "title": "ML-DL-自然语言处理基础",
            "date_published": "2022-05-09T12:48:15.000Z",
            "content_html": "",
            "tags": [
                "深度学习",
                "NLP"
            ]
        }
    ]
}